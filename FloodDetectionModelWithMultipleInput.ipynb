{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Han555/ABCRental/blob/main/FloodDetectionModelWithMultipleInput.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBja_nnhoCGX",
        "outputId": "0fa3b349-69c9-4b99-ad9a-ad30718a78e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "eWg2uADipN4w",
        "outputId": "60604e8e-4c07-43f8-f0bc-0f28ae097118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3327 files belonging to 2 classes.\n",
            "Using 2329 files for training.\n",
            "Using 998 files for validation.\n",
            "['False', 'True']\n",
            "0       0\n",
            "1       1\n",
            "2       0\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "2324    1\n",
            "2325    0\n",
            "2326    1\n",
            "2327    0\n",
            "2328    0\n",
            "Length: 2329, dtype: int32\n",
            "{0: 0.725093399750934, 1: 1.6106500691562933}\n",
            "Epoch 1/10\n",
            "73/73 [==============================] - 226s 3s/step - loss: 0.8313 - accuracy: 0.6587 - val_loss: 0.5955 - val_accuracy: 0.7505\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 146s 2s/step - loss: 0.6113 - accuracy: 0.6947 - val_loss: 0.5967 - val_accuracy: 0.6824\n",
            "Epoch 3/10\n",
            " 2/73 [..............................] - ETA: 1:58 - loss: 0.5687 - accuracy: 0.6719"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-34f5e7affc24>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m history=model.fit(train_ds,\n\u001b[0m\u001b[1;32m     40\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import keras.utils\n",
        "import pandas as pd\n",
        "from sklearn.utils import class_weight\n",
        "from matplotlib import pyplot as plt\n",
        "learning_rate=0.00001\n",
        "\n",
        "model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Flood Detection/vh_model.h5')\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "dataDirectory='/content/drive/MyDrive/Colab Notebooks/Flood Detection/VH Img/'\n",
        "train_ds,val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataDirectory,    \n",
        "    validation_split=0.3,\n",
        "    seed=123456,\n",
        "    subset='both',    \n",
        "    color_mode='grayscale')\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "dataset_unbatched = tuple(train_ds.unbatch())\n",
        "labels = []\n",
        "for (image,label) in dataset_unbatched:\n",
        "    labels.append(label.numpy())\n",
        "labels = pd.Series(labels)\n",
        "\n",
        "# adjustments\n",
        "count = labels.value_counts().sort_index()\n",
        "count.index = train_ds.class_names\n",
        "print(labels)\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                 classes=np.unique(labels),\n",
        "                                                 y=labels)\n",
        "\n",
        "class_weights = dict(zip(np.unique(labels), class_weights))\n",
        "print(class_weights)\n",
        "history=model.fit(train_ds,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=val_ds,\n",
        "          class_weight=class_weights)\n",
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.show()\n",
        "\n",
        "imagePath='/content/drive/MyDrive/Colab Notebooks/Flood Detection/VH Img/True/True-VH-sen12floods_s1_labels_0137_2019_03_07.png'\n",
        "test_image = keras.utils.load_img(imagePath,color_mode=\"grayscale\") \n",
        "test_image = keras.utils.img_to_array(test_image)\n",
        "input_arr = np.array([test_image])\n",
        "#predict the result\n",
        "result = model.predict(input_arr)\n",
        "print(np.where(result > 0.5, 'True','False'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeOjsTcR0rWV",
        "outputId": "9a1e3d3d-934c-46a6-c04e-e801d3d15002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37\n",
            "37\n",
            "37\n",
            "Model: \"merged_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " conv2d_12_input (InputLayer)   [(None, None, None,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " conv2d_8_input (InputLayer)    [(None, None, None,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, None, None,   320         ['conv2d_12_input[0][0]']        \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, None, None,   320         ['conv2d_8_input[0][0]']         \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, None, None,   0          ['conv2d_12[0][0]']              \n",
            " )                              32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, None, None,   0          ['conv2d_8[0][0]']               \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, None, None,   9248        ['max_pooling2d_12[0][0]']       \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, None, None,   9248        ['max_pooling2d_8[0][0]']        \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooling2D  (None, None, None,   0          ['conv2d_13[0][0]']              \n",
            " )                              32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, None, None,   0          ['conv2d_9[0][0]']               \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, None, None,   18496       ['max_pooling2d_13[0][0]']       \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, None, None,   18496       ['max_pooling2d_9[0][0]']        \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooling2D  (None, None, None,   0          ['conv2d_14[0][0]']              \n",
            " )                              64)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, None, None,   0          ['conv2d_10[0][0]']              \n",
            " )                              64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, None, None,   73856       ['max_pooling2d_14[0][0]']       \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, None, None,   73856       ['max_pooling2d_10[0][0]']       \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooling2D  (None, None, None,   0          ['conv2d_15[0][0]']              \n",
            " )                              128)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, None, None,   0          ['conv2d_11[0][0]']              \n",
            " )                              128)                                                              \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, None, None,   0           ['max_pooling2d_15[0][0]']       \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, None, None,   0           ['max_pooling2d_11[0][0]']       \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " global_max_pooling2d_3 (Global  (None, 128)         0           ['dropout_6[0][0]']              \n",
            " MaxPooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " global_max_pooling2d_2 (Global  (None, 128)         0           ['dropout_4[0][0]']              \n",
            " MaxPooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 128)          0           ['global_max_pooling2d_3[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 128)          0           ['global_max_pooling2d_2[0][0]'] \n",
            "                                                                                                  \n",
            " npl_dense_1_input (InputLayer)  [(None, 5)]         0           []                               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 64)           8256        ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           8256        ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " npl_dense_1 (Dense)            (None, 8)            48          ['npl_dense_1_input[0][0]']      \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 64)           0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " npl_dense_2 (Dense)            (None, 4)            36          ['npl_dense_1[0][0]']            \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 1)            65          ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            65          ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " npl_output_layer (Dense)       (None, 1)            5           ['npl_dense_2[0][0]']            \n",
            "                                                                                                  \n",
            " concatenated_layer (Concatenat  (None, 3)           0           ['dense_7[0][0]',                \n",
            " e)                                                               'dense_5[0][0]',                \n",
            "                                                                  'npl_output_layer[0][0]']       \n",
            "                                                                                                  \n",
            " output_layer (Dense)           (None, 1)            4           ['concatenated_layer[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 220,575\n",
            "Trainable params: 220,575\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 5s 671ms/step - loss: 0.8285 - accuracy: 0.4324 - val_loss: 0.8999 - val_accuracy: 0.4286\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 2s 377ms/step - loss: 0.8250 - accuracy: 0.4324 - val_loss: 0.8975 - val_accuracy: 0.4286\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 2s 352ms/step - loss: 0.8222 - accuracy: 0.4324 - val_loss: 0.8953 - val_accuracy: 0.4286\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 2s 347ms/step - loss: 0.8199 - accuracy: 0.4324 - val_loss: 0.8933 - val_accuracy: 0.4286\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 2s 353ms/step - loss: 0.8192 - accuracy: 0.4324 - val_loss: 0.8913 - val_accuracy: 0.4286\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 2s 359ms/step - loss: 0.8181 - accuracy: 0.4324 - val_loss: 0.8891 - val_accuracy: 0.4286\n",
            "Epoch 7/20\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.utils import Sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "import re\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "\n",
        "\n",
        "seed=123456\n",
        "\n",
        "train_ratio = 0.75\n",
        "validation_ratio = 0.15\n",
        "test_ratio = 0.10\n",
        "learning_rate=0.0001\n",
        "\n",
        "\n",
        "\n",
        "df_dir='/content/drive/MyDrive/Colab Notebooks/Flood Detection/sen12floods_s1_labels_processed.csv'\n",
        "df=pd.read_csv(df_dir)\n",
        "df=df.head(50)\n",
        "\n",
        "\n",
        "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"],utc=True)\n",
        "\n",
        "# Convert to Unix timestamp seconds\n",
        "df[\"datetime\"] = (df[\"datetime\"] - pd.Timestamp(\"1970-01-01\",tz='utc')) // pd.Timedelta(\"1s\")\n",
        "\n",
        "def process_attributes(train,val,test):\n",
        "  categorical=['bbox_0','bbox_1','bbox_2','bbox_3']\n",
        "  \n",
        "  cs = MinMaxScaler(feature_range=(-1, 1))\n",
        "  trainContinuous = cs.fit_transform(train[\"datetime\"].values.reshape(-1, 1))\n",
        "  valContinuous = cs.transform(val[\"datetime\"].values.reshape(-1, 1))\n",
        "  testContinuous = cs.transform(test[\"datetime\"].values.reshape(-1, 1))\n",
        "\n",
        "  trainCategorical = cs.fit_transform(train[categorical])\n",
        "  valCategorical = cs.transform(val[categorical])\n",
        "  testCategorical = cs.transform(test[categorical])\n",
        "\n",
        "  trainX = np.hstack([trainCategorical, trainContinuous])\n",
        "  valX = np.hstack([valCategorical, valContinuous])\n",
        "  testX = np.hstack([testCategorical, testContinuous])\n",
        "\t# return the concatenated training and testing data\n",
        "  return (trainX, valX,testX)\n",
        "\n",
        "vh_images=[]\n",
        "vv_images=[]\n",
        "  \n",
        "for i,r in df.iterrows():\n",
        "  a = keras.utils.load_img(r.vh_img_href,color_mode=\"grayscale\")\n",
        "  a = a.crop((0,0,a.size[0],a.size[1]-10))\n",
        "  a = a.resize((256,256))\n",
        "  b = keras.utils.load_img(r.vv_img_href,color_mode=\"grayscale\")\n",
        "  b = b.crop((0,0,b.size[0],b.size[1]-10))\n",
        "  b = b.resize((256,256))\n",
        "  ar=keras.utils.img_to_array(a)\n",
        "  ag = ar.astype('float32')\n",
        "  ag /= 255\n",
        "\n",
        "  br=keras.utils.img_to_array(b)\n",
        "  bg = br.astype('float32')\n",
        "  bg /= 255\n",
        "  vh_images.append(ag)\n",
        "  vv_images.append(bg)\n",
        "\n",
        "\n",
        "split = train_test_split(df, vh_images, test_size=1 - train_ratio, random_state=42)\n",
        "(trainAttrX, valAttrX, trainImagesVH, valImagesVH) = split\n",
        "split = train_test_split(valAttrX, valImagesVH, test_size=test_ratio/(test_ratio + validation_ratio), random_state=43)\n",
        "(valAttrX, testAttrX, valImagesVH, testImagesVH) = split\n",
        "\n",
        "split = train_test_split(df, vv_images, test_size=0.25, random_state=42)\n",
        "(trainAttrX, valAttrX, trainImagesVV, valImagesVV) = split\n",
        "split = train_test_split(valAttrX, valImagesVV, test_size=test_ratio/(test_ratio + validation_ratio), random_state=43)\n",
        "(valAttrX, testAttrX, valImagesVV, testImagesVV) = split\n",
        "\n",
        "\n",
        "#print(trainAttrX)\n",
        "trainY = trainAttrX[\"flood\"]\n",
        "valY = valAttrX[\"flood\"]\n",
        "testY = testAttrX[\"flood\"]\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                 classes=np.unique(trainY),\n",
        "                                                 y=trainY)\n",
        "model_weight=dict(zip(np.unique(trainY),class_weights))\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "trainY = labelencoder.fit_transform(trainY) \n",
        "valY = labelencoder.transform(valY) \n",
        "testY = labelencoder.transform(testY) \n",
        "\n",
        "trainY = np.asarray(trainY).astype(np.float32)\n",
        "valY = np.asarray(valY).astype(np.float32)\n",
        "testY = np.asarray(testY).astype(np.float32)\n",
        "\n",
        "trainAttrX,valAttrX,testAttrX=process_attributes(trainAttrX,valAttrX,testAttrX)\n",
        "\n",
        "print(len(trainImagesVH))\n",
        "print(len(trainImagesVV))\n",
        "print(len(trainY))\n",
        " \n",
        "# define our MLP network\n",
        "def create_mlp(dim, regress=False):\n",
        "\t# define our MLP network\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(8, input_dim=dim, activation=\"relu\",name=\"npl_dense_1\"))\n",
        "\tmodel.add(Dense(4, activation=\"relu\",name=\"npl_dense_2\"))\n",
        "\tmodel.add(Dense(1, activation=\"sigmoid\",name=\"npl_output_layer\"))\n",
        "\treturn model\n",
        "\n",
        "\n",
        "vh_model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Flood Detection/vh_model.h5')\n",
        "vh_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "vv_model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Flood Detection/vv_model.h5')\n",
        "vv_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "mlp_model = create_mlp(trainAttrX.shape[1])\n",
        "#Merging model A and B\n",
        "merge_layer = concatenate([vh_model.output,vv_model.output,mlp_model.output],name=\"concatenated_layer\")\n",
        "\n",
        "#Final Layer\n",
        "output_layer = Dense(1, activation = \"sigmoid\", name = \"output_layer\")(merge_layer)\n",
        "\n",
        "\n",
        "#Model Definition \n",
        "merged = Model(inputs=[(vh_model.input,vv_model.input,mlp_model.input)],outputs=[output_layer], name = \"merged_model\")\n",
        "\n",
        "#Model Details\n",
        "merged.summary()\n",
        "keras.utils.plot_model(merged, \"merged_architecture.png\", show_shapes=True)\n",
        "\n",
        "\n",
        "\n",
        "merged.compile(loss=keras.losses.binary_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "vh_input_np=np.array(trainImagesVH,np.float32)\n",
        "vv_input_np=np.array(trainImagesVV,np.float32)\n",
        "\n",
        "vh_val_np=np.array(valImagesVH,np.float32)\n",
        "vv_val_np=np.array(valImagesVV,np.float32)\n",
        "\n",
        "vh_test_np=np.array(testImagesVH,np.float32)\n",
        "vv_test_np=np.array(testImagesVV,np.float32)\n",
        "\n",
        "history=merged.fit(x=[vh_input_np,vv_input_np,trainAttrX],\n",
        "          y=trainY,\n",
        "          batch_size=32,\n",
        "          validation_batch_size=32,\n",
        "          class_weight=model_weight,\n",
        "          epochs=20,\n",
        "          validation_data=([vh_val_np,vv_val_np,valAttrX],valY),\n",
        "          verbose=1)\n",
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.show()\n",
        "\n",
        "score = model.evaluate(([vh_test_np,vv_test_np,testAttrX],testY), verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1P5t_6VbM-8_MzjJ2unv5HWaofIP16a4q",
      "authorship_tag": "ABX9TyPAj9tmKhCOJu45oyDozB/F",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}